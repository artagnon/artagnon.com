<!DOCTYPE html><html lang="en">
  <head>
    <title>An introduction to auto-vectorization with LLVM</title>
    <meta charset="utf-8">
    <meta name="description" content="Ramkumar Ramachandra&#39;s personal website">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index,follow">
    <link rel="icon" type="image/x-icon" href="/dist/favicon.ico">
    <link rel="apple-touch-icon" sizes="58x58" href="/dist/touch-icon-iphone.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/dist/touch-icon-ipad.png">
    <link rel="apple-touch-icon" sizes="167x167" href="/dist/touch-icon-ipad-retina.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/dist/touch-icon-iphone-retina.png">
    <link rel="stylesheet" href="/dist/style.min.css">
    <link rel="stylesheet" href="/dist/rouge.min.css">
    <script defer="" src="https://cdn.jsdelivr.net/npm/cash-dom@8/dist/cash.min.js"></script>
    <script defer="" src="https://cdn.jsdelivr.net/npm/dayjs@1/dayjs.min.js"></script>
    <script defer="" src="https://cdn.jsdelivr.net/npm/dayjs@1/plugin/relativeTime.js"></script>
    <script defer="" src="/dist/script.min.js"></script>
    <script defer="" data-domain="artagnon.com" src="https://analytics.artagnon.com/js/script.js"></script>
  <style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}
</style></head>
  <body class="wrapper">
    <nav><a href="/"><img id="logo" src="/dist/artagnon.com.svg" alt="home" width="317" height="390"></a><img id="more" src="/dist/icon.more.svg" alt="menu" width="16" height="74">
      <ul>
        <li>
          <span class="navidx">01</span><a href="/art">Art</a>
        </li>
        <li>
          <span class="navidx">02</span><a href="/computing">Computing</a>
        </li>
        <li>
          <span class="navidx">03</span><a href="/logic">Logic</a>
        </li>
      </ul>
    </nav>
    <main>
      <header>
        <h1>
          An introduction to auto-vectorization with LLVM
        </h1>
        <div id="metadata">
          <span id="timestamp"><time class="end" datetime="2024-06-27">Thu, 27 Jun 2024 20:00:00 +0100</time></span>
        </div>
      </header>
      <article>
        <p>
          Most modern general purpose CPUs have a vector processing unit (VPU). This unit contains vector registers that can hold multiple integers or floats, and instructions that operate on vector registers. Given two vector registers containing N floats each â€ , the VPU can perform a single instruction to operate on these two vector registers and store the result in another vector register. Without a VPU, this operation would require N instructions operating on two floating-point registers each relying on the floating-point unit (FPU), or arithmetic logic unit (ALU) in the case of integers.
        </p>
        <p>
          Major instruction set architectures have vector extensions, and corresponding instructions for the VPU. Examples include x86's SSE/AVX, AArch64's SVE/Neon, and the latest entrant is RISC-V's RVV. In order to generate vector instructions, the programmer could adapt their code to use standardized vector intrinsics. To illustrate, suppose the programmer had the following source code:
        </p>
        <pre><code class="highlight"><span class="kt">void</span> <span class="nf">saxpy_golden</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">iv</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iv</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">iv</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">iv</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">iv</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">iv</span><span class="p">];</span>
<span class="p">}</span></code></pre>
        <p>
          If they wanted to use <a href="https://github.com/riscv-non-isa/rvv-intrinsic-doc">RISC-V vector intrinsics</a> to vectorize it, this is how they would adapt the code:
        </p>
        <pre><code class="highlight"><span class="kt">void</span> <span class="nf">saxpy_vec</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">vl</span><span class="p">;</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span> <span class="n">n</span> <span class="o">-=</span> <span class="n">vl</span><span class="p">,</span> <span class="n">x</span> <span class="o">+=</span> <span class="n">vl</span><span class="p">,</span> <span class="n">y</span> <span class="o">+=</span> <span class="n">vl</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">vl</span> <span class="o">=</span> <span class="n">__riscv_vsetvl_e32m8</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
    <span class="n">vfloat32m8_t</span> <span class="n">vx</span> <span class="o">=</span> <span class="n">__riscv_vle32_v_f32m8</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">vl</span><span class="p">);</span>
    <span class="n">vfloat32m8_t</span> <span class="n">vy</span> <span class="o">=</span> <span class="n">__riscv_vle32_v_f32m8</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">vl</span><span class="p">);</span>
    <span class="n">__riscv_vse32_v_f32m8</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">__riscv_vfmacc_vf_f32m8</span><span class="p">(</span><span class="n">vy</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">vx</span><span class="p">,</span> <span class="n">vl</span><span class="p">),</span> <span class="n">vl</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre>
        <p>
          As is evident, this process of hand-vectorizing code is very difficult and error-prone for non-trivial programs. The process is analogous to writing assembly instead of writing the source language and letting the compiler generate assembly. Indeed, compilers today auto-vectorize code, and for the purposes of illustration, let us use Clang/LLVM. First, the source language is lowered to target-independent LLVM IR by Clang, which is the frontend. Next, the vectorizers in the middle-end of LLVM operate on this LLVM IR without vectors in them, and produce LLVM IR with vectors in them. The vectorized LLVM IR is finally lowered to target-specific assembly by the backend of LLVM.
        </p>
        <p>
          Let us take the same example of <mark>saxpy_golden</mark>, and see how the loop looks in LLVM IR without vectorization:
        </p>
        <pre><code class="highlight"><span class="nl">loop:</span>
  <span class="nv">%iv</span> <span class="p">=</span> <span class="k">phi</span> <span class="kt">i64</span> <span class="p">[</span> <span class="m">0</span><span class="p">,</span> <span class="nv">%entry</span> <span class="p">],</span> <span class="p">[</span> <span class="nv">%iv.next</span><span class="p">,</span> <span class="nv">%loop</span> <span class="p">]</span>
  <span class="nv">%gep.x</span> <span class="p">=</span> <span class="k">getelementptr</span> <span class="k">inbounds</span> <span class="kt">float</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%x</span><span class="p">,</span> <span class="kt">i64</span> <span class="nv">%iv</span>
  <span class="nv">%load.x</span> <span class="p">=</span> <span class="k">load</span> <span class="kt">float</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%gep.x</span>
  <span class="nv">%gep.y</span> <span class="p">=</span> <span class="k">getelementptr</span> <span class="k">inbounds</span> <span class="kt">float</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%y</span><span class="p">,</span> <span class="kt">i64</span> <span class="nv">%iv</span>
  <span class="nv">%load.y</span> <span class="p">=</span> <span class="k">load</span> <span class="kt">float</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%gep.y</span>
  <span class="nv">%fmuladd</span> <span class="p">=</span> <span class="k">tail</span> <span class="k">call</span> <span class="kt">float</span> <span class="vg">@llvm.fmuladd.f32</span><span class="p">(</span>
    <span class="kt">float</span> <span class="nv">%a</span><span class="p">,</span> <span class="kt">float</span> <span class="nv">%load.x</span><span class="p">,</span> <span class="kt">float</span> <span class="nv">%load.y</span><span class="p">)</span>
  <span class="k">store</span> <span class="kt">float</span> <span class="nv">%fmuladd</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%gep.y</span>
  <span class="nv">%iv.next</span> <span class="p">=</span> <span class="k">add</span> <span class="k">nuw</span> <span class="kt">i64</span> <span class="nv">%iv</span><span class="p">,</span> <span class="m">1</span>
  <span class="nv">%exitcond</span> <span class="p">=</span> <span class="k">icmp</span> <span class="k">eq</span> <span class="kt">i64</span> <span class="nv">%iv.next</span><span class="p">,</span> <span class="nv">%n</span>
  <span class="k">br</span> <span class="kt">i1</span> <span class="nv">%exitcond</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%exit</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%loop</span></code></pre>
        <p>
          The first line, <mark>loop:</mark>, is like a label in C, to which branch instructions (<mark>br</mark>) can jump to. The next line is creating a new variable <mark>%iv</mark> using a <mark>phi</mark> to select either <mark>0</mark> when jumping from the <mark>entry</mark> block (not shown), or <mark>%iv.next</mark> when jumping from the back-edge of the loop: this is the induction variable of the loop. Since <mark>x</mark> and <mark>y</mark> are pointers (marked by the type <mark>ptr</mark>), we see <mark>getelementptr</mark> instructions that act as the address computations: so, <mark>%gep.x</mark> is <mark>%x + %iv</mark>, and <mark>%gep.y</mark> is <mark>%y + %iv</mark>. The <mark>load</mark> instructions derefence the pointer: so, <mark>%load.x</mark> is <mark>x[iv]</mark> and <mark>load.y</mark> is <mark>y[iv]</mark>; both are of type <mark>f32</mark>, or <mark>float</mark>. <mark>@llvm.fmuladd.f32</mark> is the computation, which does a <mark>a * x[iv] + y[iv]</mark>, and the <mark>store</mark> writes the result <mark>%fmuladd</mark> back into <mark>%gep.y</mark>. The last three instructions make the <mark>loop</mark> block a loop: <mark>%iv.next = %iv + 1</mark> is the "next value" of the loop induction variable, and <mark>%exitcond</mark> is a boolean (marked by the type <mark>i1</mark>, integer with bitwidth 1) that acts as the exit-condition of the loop. <mark>%exitcond</mark> is computed as an integer-equal-comparison between <mark>%iv.next</mark> and <mark>%n</mark>, where <mark>n</mark> is the total number of iterations of the loop. Finally, there is a branch instruction that jumps to either the <mark>exit</mark> block (not shown), or back to the <mark>loop</mark> block (this is the back-edge of the loop), depending on the exit condtion.
        </p>
        <p>
          This is how it changes after vectorization:
        </p>
        <pre><code class="highlight"><span class="nl">loop.preaheder:</span>
  <span class="nv">%n.and.minus4</span> <span class="p">=</span> <span class="k">and</span> <span class="kt">i64</span> <span class="nv">%n</span><span class="p">,</span> <span class="m">-4</span>
  <span class="nv">%a.vec.tmp</span> <span class="p">=</span> <span class="k">insertelement</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="err">poison</span><span class="p">,</span> <span class="kt">float</span> <span class="nv">%a</span><span class="p">,</span> <span class="kt">i64</span> <span class="m">0</span>
  <span class="nv">%a.vec</span> <span class="p">=</span> <span class="k">shufflevector</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="nv">%a.vec.tmp</span><span class="p">,</span>
    <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="err">poison</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">i32</span><span class="p">&gt;</span> <span class="k">zeroinitializer</span>
  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%loop</span>

<span class="nl">loop:</span>
  <span class="nv">%iv</span> <span class="p">=</span> <span class="k">phi</span> <span class="kt">i64</span> <span class="p">[</span> <span class="m">0</span><span class="p">,</span> <span class="nv">%loop.preaheder</span> <span class="p">],</span> <span class="p">[</span> <span class="nv">%iv.next</span><span class="p">,</span> <span class="nv">%loop</span> <span class="p">]</span>
  <span class="nv">%gep.x</span> <span class="p">=</span> <span class="k">getelementptr</span> <span class="k">inbounds</span> <span class="kt">float</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%x</span><span class="p">,</span> <span class="kt">i64</span> <span class="nv">%iv</span>
  <span class="nv">%load.x</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;,</span> <span class="err">ptr</span> <span class="nv">%gep.x</span>
  <span class="nv">%gep.y</span> <span class="p">=</span> <span class="k">getelementptr</span> <span class="k">inbounds</span> <span class="kt">float</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%y</span><span class="p">,</span> <span class="kt">i64</span> <span class="nv">%iv</span>
  <span class="nv">%load.y</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;,</span> <span class="err">ptr</span> <span class="nv">%gep.y</span>
  <span class="nv">%fmuladd</span> <span class="p">=</span> <span class="k">tail</span> <span class="k">call</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="vg">@llvm.fmuladd.v4f32</span><span class="p">(</span>
    <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="nv">%a.vec</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="nv">%load.x</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="nv">%load.y</span><span class="p">)</span>
  <span class="k">store</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="nv">%fmuladd</span><span class="p">,</span> <span class="err">ptr</span> <span class="nv">%gep.y</span>
  <span class="nv">%iv.next</span> <span class="p">=</span> <span class="k">add</span> <span class="k">nuw</span> <span class="kt">i64</span> <span class="nv">%iv</span><span class="p">,</span> <span class="m">4</span>
  <span class="nv">%exitcond</span> <span class="p">=</span> <span class="k">icmp</span> <span class="k">eq</span> <span class="kt">i64</span> <span class="nv">%iv.next</span><span class="p">,</span> <span class="nv">%n.and.minus4</span>
  <span class="k">br</span> <span class="kt">i1</span> <span class="nv">%exitcond</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%exit</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%loop</span></code></pre>
        <p>
          The loop now has a <mark>loop.preheader</mark> block containing an <mark>%n.and.minus4</mark> to handle the case when <mark>n</mark> is not a multiple of four. It also contains an <mark>insertelement</mark> and <mark>shufflevector</mark>, which essentially fill the vector <mark>%a.vec</mark> (that has type <mark>&lt;4 x float&gt;</mark>) with four copies of <mark>%a</mark>. The difference in the loop is that <mark>%iv.next</mark> is now <mark>%iv + 4</mark>, since it operates on four floats at a time, cutting the number of iterations by a factor of four. The <mark>load</mark> instructions are now loading four floats at a time, and the vector variant of <mark>@llvm.fmuladd.f32</mark>, which is <mark>@llvm.fmuladd.v4f32</mark>, does a <mark>%a.vec * %load.x + %load.y</mark>, operating on a vector of four floats at a time.
        </p>
        <p>
          The vectorizer in LLVM is quite sophisticated, and it is fascinating how it manages to vectorize non-trivial examples. To walk through a simple but non-trivial example, consider:
        </p>
        <pre><code class="highlight"><span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">?</span> <span class="mi">0</span> <span class="o">:</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span></code></pre>
        <p>
          Inspecting the <a href="https://godbolt.org/z/qq39c1PT7">output</a>, we can see what the vectorizer has done. First, we see a new <mark>phi</mark>:
        </p>
        <pre><code class="highlight"><span class="nv">%vec.ind</span> <span class="p">=</span> <span class="k">phi</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">i64</span><span class="p">&gt;</span> <span class="p">[</span> <span class="p">&lt;</span><span class="kt">i64</span> <span class="m">0</span><span class="p">,</span> <span class="kt">i64</span> <span class="m">1</span><span class="p">,</span> <span class="kt">i64</span> <span class="m">2</span><span class="p">,</span> <span class="kt">i64</span> <span class="m">3</span><span class="p">&gt;,</span> <span class="nv">%vector.ph</span> <span class="p">],</span>
  <span class="p">[</span> <span class="nv">%vec.ind.next</span><span class="p">,</span> <span class="nv">%vector.body</span> <span class="p">]</span></code></pre>
        <p>
          It has created a new vector induction variable vector, corresponding to <mark>i</mark>, with four elements, since it has decided to vectorize with a factor of 4. Since <mark>%vec.ind</mark> is an integer, and the vectors are <mark>float</mark>, it has done a integer-to-floating-point conversion:
        </p>
        <pre><code class="highlight"><span class="nv">%10</span> <span class="p">=</span> <span class="k">uitofp</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">i64</span><span class="p">&gt;</span> <span class="nv">%9</span> <span class="k">to</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span></code></pre>
        <p>
          For the conditional itself, it has used a <mark>select</mark> to choose either <mark>0</mark> or the loaded value:
        </p>
        <pre><code class="highlight"><span class="nv">%15</span> <span class="p">=</span> <span class="k">select</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">i1</span><span class="p">&gt;</span> <span class="nv">%12</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="k">zeroinitializer</span><span class="p">,</span>
  <span class="p">&lt;</span><span class="m">4</span> <span class="p">x</span> <span class="kt">float</span><span class="p">&gt;</span> <span class="nv">%wide.load1</span></code></pre>
        <hr class="ellipses">
        <p>
          For the rest of this article, let us inspect some factors that could get in the way when the loop is expected to be vectorized, omitting cases where the loop is either obviously impossible or unprofitable to vectorize.
        </p>
        <ol class="olitems" type="none" start="1">
          <li>
            The iteration count. In most real-world code, the exact iteration count is unknown and the auto-vectorizers can deal with this. Auto-vectorizers can also deal with non-power-of-2 iteration counts by inserting a scalar epilogue with the remaining iterations. However, if the iteration count of the loop is computable and too small, the loop might get unrolled instead of vectorized.
          </li>
          <li>
            Aliasing information. If there isn't sufficient information to determine whether memory accesses in the loop are aliased to each other, runtime checks may be generated, or auto-vectorization might fail completely because insertion of runtime checks make it unprofitable to vectorize.
          </li>
        </ol>
        <p>
          To illustrate, let's modify <mark>saxpy_golden</mark> as follows:
        </p>
        <pre><code class="highlight"><span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">];</span></code></pre>
        <p>
          Then, running <mark>clang -O3 -fno-unroll-loops -mllvm -vectorize-loops=false -emit-llvm -S test.c -o test.ll</mark> followed by <mark>opt -passes=loop-vectorize -debug-only=loop-vectorize test.ll</mark> <a href="https://godbolt.org/z/8jn95qbxT">outputs</a>:
        </p>
        <pre><code class="highlight">LV: Found a loop with a very small trip count.
  This loop is worth vectorizing only if no
  scalar iteration overheads are incurred.
LV: Found trip count: 3
LV: Not vectorizing</code></pre>
        <p>
          The overhead it is talking about is runtime checks it needs to add. Adding <mark>restrict</mark> to the pointers would remove the overhead, and allow it to be vectorized:
        </p>
        <pre><code class="highlight"><span class="kt">void</span> <span class="n">saxpy_golden</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="kr">restrict</span> <span class="n">x</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="kr">restrict</span> <span class="n">y</span><span class="p">)</span></code></pre>
        <p>
          Even if we were to ramp up the iteration count to <mark>17</mark>, unrolling the loop would be preferred over vectorization. Forcing it not to unroll loops using <mark>-fno-unroll-loops</mark> as before results in successful vectorization. The final <a href="https://godbolt.org/z/3Torh4ddE">output</a> contains a scalar version of the loop as well, marked by <mark>scalar.ph</mark>, which is required as 17 isn't divisible by 4.
        </p>
        <ol class="olitems" type="none" start="3">
          <li>
            The memory access pattern. A good rule of thumb write loops with uniform row-major access, and avoid complex indexing arithmetic.
          </li>
        </ol>
        <p>
          The vectorizer has no issues with the following case:
        </p>
        <pre><code class="highlight"><span class="kt">void</span> <span class="nf">test</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">m</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span>
          <span class="k">const</span> <span class="kt">float</span> <span class="o">**</span><span class="kr">restrict</span> <span class="n">x</span><span class="p">,</span> <span class="kt">float</span> <span class="o">**</span><span class="kr">restrict</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span>
      <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="p">}</span></code></pre>
        <p>
          Now, let's change the assignment statement in the loop to:
        </p>
        <pre><code class="highlight"><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">];</span></code></pre>
        <p>
          This is unfortunately not vectorized by LLVM, but there is no reason this is not theoretically vectorizable. The reason for this is that an analysis that is used to prove legality of vectorization in LLVM, called LoopAccessAnalysis, is unable to find the bounds of the memory access. Running <mark>opt -passes=loop-vectorize test.ll -disable-output -debug-only=loop-accesses</mark> <a href="https://godbolt.org/z/5T9docTfq">outputs</a>:
        </p>
        <pre><code class="highlight">LAA: We can't vectorize because we can't find the array bounds.</code></pre>
        <ol class="olitems" type="none" start="4">
          <li>
            Conditionals within the loop. Certain conditionals are possible to vectorize by either using <mark>select</mark>, or masking values in the vector using the condition. There is no way to tell if a certain conditional will be vectorized in advance, and depends on whether the pattern is implemented in LLVM's vectorizer.
          </li>
        </ol>
        <p>
          LLVM is able to vectorize the example discussed previously:
        </p>
        <pre><code class="highlight"><span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">?</span> <span class="mi">0</span> <span class="o">:</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span></code></pre>
        <p>
          Unfortunately, it is unable to vectorize this:
        </p>
        <pre><code class="highlight"><span class="kt">size_t</span> <span class="n">rdx</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="n">rdx</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">?</span> <span class="n">i</span> <span class="o">:</span> <span class="n">rdx</span><span class="p">;</span>
<span class="k">return</span> <span class="n">rdx</span><span class="p">;</span></code></pre>
        <p>
          The <a href="https://godbolt.org/z/Wfjr6ofrf">reason</a> is as good as "it is unimplemented":
        </p>
        <pre><code class="highlight">LV: Not vectorizing: Found an unidentified PHI
  %10 = phi i64 [ %16, %8 ], [ 3, %.preheader ]</code></pre>
        <ol class="olitems" type="none" start="5">
          <li>
            Whether the loop is canonical. If, for instance, the loop has multiple exits, LLVM cannot auto-vectorize it.
          </li>
        </ol>
        <p>
          LLVM struggles with early-exit loops, although there is no reason this is not possible to vectorize:
        </p>
        <pre><code class="highlight"><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="k">break</span><span class="p">;</span>
  <span class="p">}</span>
<span class="k">return</span> <span class="n">i</span><span class="p">;</span></code></pre>
        <p>
          The <a href="https://godbolt.org/z/Yfe3PxzPY">reason</a> is as good as "it is unimplemented":
        </p>
        <pre><code class="highlight">LV: Found an outside user for :   %.lcssa = phi float [ %11, %6 ]
LV: Not vectorizing: could not determine number of loop iterations.</code></pre>
        <ol class="olitems" type="none" start="6">
          <li>
            Function calls within the loop. Except for calls to LLVM intrinsics (like the <mark>@llvm.fmuladd</mark> in the example discussed previously), the auto-vectorizer will fail if there are function calls within the loop that it didn't inline.
          </li>
        </ol>
        <p>
          LLVM cannot vectorize:
        </p>
        <pre><code class="highlight"><span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"%f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span></code></pre>
        <p>
          AArch64 and RISC-V don't include a vector instruction for <mark>printf</mark> in their instruction set, and this is a fundamental limitation of the instruction set.
        </p>
        <pre><code class="highlight">LV: Not vectorizing: Found a non-intrinsic callsite
  %13 = tail call i32 (ptr, ...) @printf(
    ptr noundef nonnull dereferenceable(1) @.str,
    double noundef %12)</code></pre>
        <p>
          An example of a vector instruction that's included in both AArch64 and RISC-V is <mark>lrint</mark>, and vectorizing a program with it will use the vector variant of the <mark>@llvm.lrint</mark> intrinsic in the target-independent LLVM IR. The output can be inspected on <a href="https://godbolt.org/z/foG7GsxYh">Godbolt</a>.
        </p>
        <pre><code class="highlight"><span class="kt">void</span> <span class="nf">test</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">long</span> <span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">lrint</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="p">}</span></code></pre>
        <footer>
          <ul class="footer">
            <li>
              N is a power of two, bounded by vector register width.
            </li>
          </ul>
        </footer>
      </article>
    </main>
  </body>
</html>