An introduction to auto-vectorization

Most modern general purpose CPUs have a vector processing unit (VPU). This unit contains vector registers that can hold multiple integers or floats, and instructions that operate on vector registers. Given two vector registers containing N (where N is a power of 2 bounded by vector register width on the machine) floats each, the VPU can perform a single instruction to operate on these two vector registers and store the result in another vector register. Without a VPU, this operation would require N instructions operating on two floating-point registers each, relying on the floating-point unit (FPU) or arithmetic logic unit (ALU) in the case of integers.

Major instruction set architectures have vector extensions, and corresponding instructions for the VPU. Examples include x86's SSE/AVX, AArch64's SVE/Neon, and the latest entrant is RISC-V's RVV. In order to generate vector instructions, the programmer could adapt their code to use standarized vector intrinsics. To illustrate, suppose the programmer had the following source code:

```c
void saxpy_golden(size_t n, const float a, const float *x, float *y) {
  for (size_t iv = 0; iv < n; ++iv)
    y[iv] += a * x[iv];
}
```

If they wanted to use [RISC-V vector intrinsics](https://github.com/riscv-non-isa/rvv-intrinsic-doc) to vectorize it, this is how they would adapt the code:

```c
void saxpy_vec(size_t n, const float a, const float *x, float *y) {
  for (size_t vl; n > 0; n -= vl, x += vl, y += vl) {
    vl = __riscv_vsetvl_e32m8(n);
    vfloat32m8_t vx = __riscv_vle32_v_f32m8(x, vl);
    vfloat32m8_t vy = __riscv_vle32_v_f32m8(y, vl);
    __riscv_vse32_v_f32m8(y, __riscv_vfmacc_vf_f32m8(vy, a, vx, vl), vl);
  }
}
```

This process of hand-vectorizing code is very difficult and error-prone for non-trivial programs. The process is analogous to hand-writing assembly instead of directly writing the source langauge and letting the compiler generate assembly. Indeed, compilers today auto-vectorize code, and for the purposes of illustration, let us take Clang/LLVM as an example. First, the source language is lowered to target-independent LLVM IR by Clang, which is the frontend. Next, the vectorizers in the middle-end of LLVM operate on this LLVM IR without vectors in them, and produce LLVM IR with vectors in them. The vectorized LLVM IR is finally lowered to target-specific assembly by the backend of LLVM.

Let us take the same example of `saxpy_golden`, and see how the loop looks in LLVM IR without vectorization:

```llvm
loop:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop ]
  %gep.x = getelementptr inbounds float, ptr %x, i64 %iv
  %load.x = load float, ptr %gep.x
  %gep.y = getelementptr inbounds float, ptr %y, i64 %iv
  %load.y = load float, ptr %gep.y
  %fmuladd = tail call float @llvm.fmuladd.f32(
    float %a, float %load.x, float %load.y)
  store float %fmuladd, ptr %gep.y
  %iv.next = add nuw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %exit, label %loop
```

Except for the `loop:` label and the `phi` node, every line of this IR is an instruction operating on variables (prefixed with `%`), most of which return something, and another variable is assigned the result. The last instruction, `br`, is a branching statement which jumps to either the `exit` label (not shown), or to the `loop` label, depending on the `i1` (integer with one bit, or boolean) `%exitcond`. Now, `%exitcond` is computed as an integer-equal-comparison between `%iv.next`, and `%n`: what this means is that `%exitcond` is the exit-condition for the loop, when the loop induction variable, after the increment reaches the parameter `n` in the original program, the total number of iterations. `%iv.next` is the "next value" of the induction variable, which is computed as `%iv + 1`. The reason for the fresh variable is that this IR is in single-static-assignment (SSA) form, which means that there is only ever a single definition of a value, relying on `phi` nodes to merge incoming values from different points. `%iv` is the phi node that merges the incoming value `0` when coming from the `entry:` label (not shown; preamble of the program with a branch into `loop` block), and `iv.next`, when coming from the back-edge of the loop. Since `x` and `y` are pointers, the IR has `getelementptr` and `load` instructions that essentially do the array-indexing `x[iv]` and `y[iv]`. Finally the computation on these two elements of the array are performed by `@llvm.fmuladd.f32`, which does `a * x[iv] + y[iv]`, before the final result is stored again in `y[iv]`.

This is how it changes after vectorization:

```llvm
loop.preaheder:
  %n.and.minus4 = and i64 %n, -4
  %a.vec.tmp = insertelement <4 x float> poison, float %a, i64 0
  %a.vec = shufflevector <4 x float> %a.vec.tmp,
    <4 x float> poison, <4 x i32> zeroinitializer
  br label %loop

loop:
  %iv = phi i64 [ 0, %loop.preaheder ], [ %iv.next, %loop ]
  %gep.x = getelementptr inbounds float, ptr %x, i64 %iv
  %load.x = load <4 x float>, ptr %gep.x
  %gep.y = getelementptr inbounds float, ptr %y, i64 %iv
  %load.y = load <4 x float>, ptr %gep.y
  %fmuladd = tail call <4 x float> @llvm.fmuladd.v4f32(
    <4 x float> %a.vec, <4 x float> %load.x, <4 x float> %load.y)
  store <4 x float> %fmuladd, ptr %gep.y
  %iv.next = add nuw i64 %iv, 4
  %exitcond = icmp eq i64 %iv.next, %n.and.minus4
  br i1 %exitcond, label %exit, label %loop
```

Now, the loop has a `loop.preheader` block containing an `insertelement` and `shufflevector`, which essentially fill the vector (that has type `<4 x float>`) `%a.vec` with four copies of `%a`. The difference in the loop is that `%iv.next` is now `%iv + 4`, since it operates on four floats at a time, cutting the number of iterations by a factor of four. The `load` instructions are now loading four floats at a time, and the variant of `@llvm.fmuladd.f32` is `@llvm.fmuladd.v4f32` that does a `%a.vec * %load.x + %load.y`, operating on a vector of four floats at a time.

Whether or not a candidate loop will be successfully auto-vectorized depends on several factors:

1. The iteration count. In most real-world code, the exact iteration count is unknown and the auto-vectorizers can deal with this. Auto-vectorizers can also deal with non-power-of-2 iteration counts by inserting a scalar epilogue with the remaining iterations. However, if the iteration count of the loop is computable and too small, the loop might get unrolled instead of vectorized.
2. Aliasing information. If there isn't sufficient information to determine whether arrays in the loop are aliased to each other, runtime checks may be generated, or auto-vectorization might fail completely. A good practice is to mark non-aliased pointers with `restrict` in the source code.

To illustrate, let's modify `saxpy_golden` as follows:

```c
for (size_t i = 0; i < 3; ++i)
  y[i] += a * x[i];
```

Then, running `clang -O3 -fno-unroll-loops -mllvm -vectorize-loops=false -emit-llvm -S test.c -o test.ll` followed by `opt -passes=loop-vectorize -debug-only=loop-vectorize test.ll -disable-output` outputs (abbreviated):

```
LV: Found a loop with a very small trip count.
  This loop is worth vectorizing only if no
  scalar iteration overheads are incurred.
LV: Found trip count: 3
LV: Not vectorizing
```

Adding `restrict` to the pointers would remove the overhead, and allow it to be vectorized:

```c
void test(const float a, const float *restrict x, float *restrict y)
```

Even if we were to ramp up the iteration count to `17`, unrolling the loop would be preferred over vectorization. Forcing it not to unroll loops using `-fno-unroll-loops` as before results in successful vectorization. If you want to analyze the vectorized code, run control-flow-graph simplification after loop-vectorize to get simplified output as `opt -passes=loop-vectorize,cfgsimplify -S test.ll -o test.vec.ll` â€¡ and inspect `test.vec.ll` to see a scalar version of the loop, which is required as 17 isn't divisible by 4.

3. The access pattern. A good rule of thumb write loops with uniform row-major access, and avoid complex indexing arithmetic.

To illustrate, let's modify `saxpy_golden` as follows:

```c
void test(size_t n, size_t m, const float a,
                  const float **restrict x, float **restrict y) {
  for (size_t i = 0; i < n; ++i)
    for (size_t j = i; j < m; ++j)
      y[i][j] += a * x[i][j];
}
```

Vectorized just fine.

Now, let's change the assignment statement in the loop to:

```c
y[i][j] += a * x[j][i];
```

Not vectorized:

```
LV: Can't vectorize due to memory conflicts
```

4. Conditionals within the loop. Certain `if` statements are possible to vectorize by masking values in the vector using the condition. There is no way to tell if a certain conditional will be vectorized in advance.

To illustrate, let's change `saxpy_golden` as follows:

```c
for (size_t i = 0; i < n; ++i)
  y[i] = a * x[i] + i > x[i] ? x[i] : y[i];
```

Vectorized just fine.

Now, change it to:

```
size_t rdx = 3;
for (size_t i = 0; i < n; ++i)
  rdx = (y[i] > x[i]) ? i : rdx;
return rdx;
```

Not vectorized:

```
LV: Not vectorizing: Found an unidentified PHI
  %10 = phi i64 [ %16, %8 ], [ 3, %.preheader ]
```

5. Whether the loop is canonical. If, for instance, the loop has multiple exits, LLVM cannot auto-vectorize it.

Simple example of this:

```c
for (size_t i = 0; i < n; ++i) {
  y[i] += a * x[i];
  if (x[i] > n)
    break;
}
```

Reason:

```
LV: Not vectorizing: could not determine number of loop iterations.
```

6. Function calls within the loop. Except for calls to LLVM intrinsics (like the `@llvm.fmuladd` in the above example), the auto-vectorizer will fail if there are function calls within the loop that it didn't inline.

Simple example of this:

```c
for (size_t i = 0; i < n; ++i)
  printf("%f\n", a * x[i]);
```

The reason:

```
LV: Not vectorizing: Found a non-intrinsic callsite
  %13 = tail call i32 (ptr, ...) @printf(
    ptr noundef nonnull dereferenceable(1) @.str,
    double noundef %12)
```

â€¡ Note that `opt` isn't part of a standard `clang` installation, and morever, `-debug-only` only works with a debug-build of LLVM.
