AI and the war-time economy

There are innumerable reasons to hate AI, starting with its environmental impact: the AI boom has been estimated to consume as much power as New York City, and as much water as the global consumption of bottled water in 2025. The reasons could also be personal, from leading to a loss of livelihood, to threatening the way we pursue our passions. The distaste is fueled by visible misuse, including the flood of low-quality AI-generated bug reports and PRs on open-source projects, music and books uploaded to Spotify and Amazon, papers at academic venues, and the [recent horrifying McDonalds ad](https://youtu.be/E-YwjXEVGo8?si=RcEymmyF_qWB13ks). To make things worse, there is plenty of [anecdotal evidence](https://stephenramsay.net/posts/vibe-coding.html) to suggest that AI makes an individual more productive, while there are plenty of [studies](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/) that suggest the opposite. At the same time, there is no denying that the technology is !_{very} widespread across the industry, well beyond just the software industry. For many of us, personal distaste and ethical issues has lead to a AI-denialism stance, where we [declare that AI doesn't work for anyone](https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding), and espouse [borderline conspiracy theories](https://pluralistic.net/2025/12/05/pop-that-bubble/).

The primary feature of AI to pay attention to is that it's a fuzzy non-deterministic system, and measuring productivity gains from AI at an individual level is a bit like studying witchcraft. Today, AI adoption across the industry — be it software, finance, digital humanities, law, journalism, or otherwise — is so widespread, that dismissing it as just "hype" or "herd mentality" is not a cogent position any longer. To a first approximation, corporations are rational capitalist actors looking to maximize their profits, and they are paying good money for AI products for a reason. I only see one conclusion by Occam's razor: that, for many orgs, implementing AI org-wide is a net-positive, although the results vary at an individual-level. Many orgs have run internal productivity metrics and found a 20-30% increase — and the proof is that they continue paying for AI products, even in the light of studies that suggest that AI makes individuals less productive. This would lead us to look for publicly observable metrics to correlate the fact that there's an increase in productivity across the board: for example, we might expect to see quicker software release cycles, an uptick in feature rollout or bug-fixes in products, or in open-source code. Perhaps not the not the most satisfying answer, but orgs are not increasing their production volume with AI adoption, and are instead raking in profits by lowering their costs — and the publicly observable metrics are the layoffs, hiring slump, unemployment, and under-employment in advanced economies. The other problem is that the technology is a poor fit for open-source projects, and I will expand on this next. As an economist put quite poignantly, the current situation is akin to a !_{war-time economy}, where all the defense companies are raking in profits with huge environmental costs (or the AI adopters today), while everyone else is left to survive on rations.

Open source communities work because the community members are deeply passionate about the project, and treat their work like a hobby — they take pride in their work, and there is nothing to sell. All open source projects must attract and retain new contributors every year to survive. Maintainers often do a lot of work helping new contributors, and the payoff is only seen when a new contributor continues gaining experience, and eventually grows into a maintainer themselves. This key social aspect of an open source project is the reason why AI adoption will be minimal at best: the cost of maintaining LLM-generated code outweighs the marginal benefit of adding a new feature — and since it was low-effort for the new contributor, they are less likely to stay on and learn. The cost-benefit computation is different for a corporation selling a product — revenue is directly correlated to feature rollout. The idea of corporations profiting off open source is nothing new — and in this age, all they have to do is train their LLM on our hand-crafted "artisanal" code.

The economics of AI [doesn't add up at all](https://www.wheresyoured.at/the-case-against-generative-ai/), and the technology cannot even be sold at cost — there is no denying that we live in a bubble similar to the sub-prime mortgage bubble. After the crash, a lot of everyday people will lose a significant portion of their savings for no fault of theirs, and what will probably be left are cheap compressed versions of what we have today, running on commodity hardware.

We have been very irresponsible in going down this AI path — and we're doing irreversible damage to the planet while at it. I hate AI for all the reasons outlined, and it is useless to me, as a member of the LLVM community. However, I cannot deny that the technology is widely useful and has increased the productivity of many orgs.
